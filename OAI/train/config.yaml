seed: 0
gpu: 0

data:
  folder_path: ./data/

model:
  name: "microsoft/deberta-v3-base"
  load_best_at_end: True
  metric_for_best: "eval_overall_f1"
  model_max_length: 64

log:
  strategy: "steps"
  steps: 100
  report_to: ["wandb"]
  first_step: True
  run_name: "microsoft-deberta-v3-base"
  level: "info"

train:
  overwrite_checkpoint_path: True
  num_epochs: 1
  batch_size: 8

optimizer:
  name: "adamw_torch"
  learning_rate: 3e-4
  weight_decay: 0.01

learning_rate_scheduler:
  name: "cosine"
  warmup_steps: 48

eval:
  strategy: "steps"
  steps: 100
  batch_size: 8
  delay: 0.0

save:
  strategy: "steps"
  steps: 100

test:
  batch_size: 8
