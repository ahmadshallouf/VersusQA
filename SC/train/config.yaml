seed: 0
gpu: 0

data:
  folder_path: ./data/

model:
  name: "microsoft/deberta-v3-large"
  load_best_at_end: True
  metric_for_best: "eval_f1"

log:
  strategy: "steps"
  steps: 100
  report_to: ["wandb"]
  first_step: True
  run_name: "microsoft-deberta-v3-large"
  level: "info"

train:
  overwrite_checkpoint_path: True
  num_epochs: 13
  batch_size: 16

optimizer:
  name: "adamw_torch"
  learning_rate: 0.00003
  weight_decay: 0.1

learning_rate_scheduler:
  name: "cosine"
  warmup_steps: 100

eval:
  strategy: "steps"
  steps: 100
  batch_size: 16
  delay: 0.0

save:
  strategy: "steps"
  steps: 100

test:
  batch_size: 16
